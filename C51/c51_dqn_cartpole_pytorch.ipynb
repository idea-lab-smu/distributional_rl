{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# built-in\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from collections import deque\n",
    "from copy import deepcopy\n",
    "#tihrd party\n",
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global constant\n",
    "SEED = 0\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.001\n",
    "ADAM_EPS = 0.01 / BATCH_SIZE\n",
    "\n",
    "# C51 hyperparameter\n",
    "V_MAX = 10\n",
    "V_MIN = -10\n",
    "N_ATOMS = 51\n",
    "DELTA_Z = (V_MAX - V_MIN) / (N_ATOMS - 1)\n",
    "\n",
    "# set tensorboard\n",
    "# tensorboard and tensorboardX must be installed.\n",
    "# pip install tensorboardX\n",
    "USE_TENSORBOARD = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print('cuda:', use_cuda)\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "\n",
    "# random seed\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "if USE_TENSORBOARD:\n",
    "    from tensorboardX import SummaryWriter\n",
    "    writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistrDQN(nn.Module):\n",
    "    def __init__(self, in_dim, n_actions, n_atoms):\n",
    "        super(DistrDQN, self).__init__()\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(in_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_actions * n_atoms)\n",
    "        )\n",
    "        self.log_softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "        self.register_buffer('support', torch.arange(V_MIN, V_MAX + DELTA_Z, DELTA_Z))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.dense(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out).view(out.size(0), -1, N_ATOMS)\n",
    "        out = self.log_softmax(out)\n",
    "        probs = out.exp()\n",
    "\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection(next_p, rewards, dones):\n",
    "    proj_p = np.zeros((BATCH_SIZE, N_ATOMS), dtype=np.float32)\n",
    "    for atom in range(N_ATOMS):\n",
    "        z = np.minimum(V_MAX, np.maximum(V_MIN, rewards + (V_MIN + atom * DELTA_Z) * 0.9))\n",
    "        b = (z - V_MIN) / DELTA_Z\n",
    "        l = np.floor(b).astype(np.int64)\n",
    "        u = np.ceil(b).astype(np.int64)\n",
    "\n",
    "        eq_mask = u == l\n",
    "        proj_p[eq_mask, l[eq_mask]] += next_p[eq_mask, atom]\n",
    "        ne_mask = u != l\n",
    "        proj_p[ne_mask, l[ne_mask]] += next_p[ne_mask, atom] * (u - b)[ne_mask]\n",
    "        proj_p[ne_mask, u[ne_mask]] += next_p[ne_mask, atom] * (b - l)[ne_mask]\n",
    "\n",
    "        if dones.any():\n",
    "            proj_p[dones] = 0.0\n",
    "            z = np.minimum(V_MAX, np.maximum(V_MIN, rewards[dones]))\n",
    "            b = (z - V_MIN) / DELTA_Z\n",
    "            l = np.floor(b).astype(np.int64)\n",
    "            u = np.ceil(b).astype(np.int64)\n",
    "\n",
    "            eq_mask = u == l\n",
    "            eq_dones = dones.copy()\n",
    "            eq_dones[dones] = eq_mask\n",
    "            if eq_dones.any():\n",
    "                proj_p[eq_dones, l] = 1.0\n",
    "\n",
    "            ne_mask = u != l\n",
    "            ne_dones = dones.copy()\n",
    "            ne_dones[dones] = ne_mask\n",
    "            if ne_dones.any():\n",
    "                proj_p[ne_dones, l] = (u - b)[ne_mask]\n",
    "                proj_p[ne_dones, u] = (b - l)[ne_mask]\n",
    "\n",
    "    return proj_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, tgt_net, rep_memory):\n",
    "    net.train()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=LR, eps=ADAM_EPS)\n",
    "    \n",
    "    train_data = []\n",
    "    train_data.extend(random.sample(rep_memory, BATCH_SIZE))\n",
    "    \n",
    "    dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, pin_memory=use_cuda)\n",
    "    \n",
    "    for i, (s, a, r, _s, d) in enumerate(dataloader):\n",
    "        s_batch = s.to(device).float()\n",
    "        a_batch = a.to(device).long()\n",
    "        _s_batch = _s.to(device).float()\n",
    "        rewards = r.detach().cpu().numpy()\n",
    "        dones = d.detach().cpu().numpy().astype(np.bool)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            _p_batch = tgt_net(_s_batch)\n",
    "            _weights = _p_batch * tgt_net.support\n",
    "            _q_batch = _weights.sum(dim=2)\n",
    "            _q_batch_np = _q_batch.cpu().numpy()[0]\n",
    "            _action_batch_np = np.argmax(_q_batch_np)\n",
    "            _p_best = _p_batch[range(BATCH_SIZE), _action_batch_np]\n",
    "            _p_best_np = _p_best.cpu().numpy()\n",
    "            \n",
    "        proj_p_np = projection(_p_best_np, rewards, dones)\n",
    "        proj_p = torch.tensor(proj_p_np).to(device).float()\n",
    "        \n",
    "        p_batch = net(s_batch)\n",
    "        p_acting = p_batch[range(BATCH_SIZE), a_batch.data]\n",
    "        \n",
    "        loss = -(proj_p * (p_acting + 1e-8).log()).sum(dim=1).mean()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        assert loss == loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make an environment\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "env.seed(SEED)\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "# make two nerual networks\n",
    "net = DistrDQN(obs_dim, n_actions, N_ATOMS).to(device)\n",
    "target_net = deepcopy(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play\n",
    "n_episodes = 500\n",
    "memory_size = 10000\n",
    "learn_start = 2000\n",
    "update_frq = 1\n",
    "epsilon = 1.0\n",
    "eps_min = 0.02\n",
    "total_steps = 0\n",
    "n_dones = 0\n",
    "rewards = []\n",
    "is_learned = False\n",
    "is_solved = False\n",
    "\n",
    "# make a replay memory\n",
    "rep_memory = deque(maxlen=memory_size)\n",
    "\n",
    "for i in range(n_episodes):\n",
    "    obs = env.reset()\n",
    "    ep_reward = 0\n",
    "    ep_steps = 0\n",
    "    while True:\n",
    "        env.render()\n",
    "        # epsilon greedy\n",
    "        if np.random.random() < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            target_net.eval()\n",
    "            with torch.no_grad():\n",
    "                state = torch.tensor([obs]).to(device).float()\n",
    "                probs = target_net(state)\n",
    "                weights = probs * net.support\n",
    "                q = weights.sum(dim=2)\n",
    "                q_np = q.cpu().numpy()[0]\n",
    "            action = np.argmax(q_np)\n",
    "\n",
    "        _obs, reward, done, _ = env.step(action)\n",
    "        \n",
    "        rep_memory.append((obs, action, reward, _obs, done))\n",
    "        \n",
    "        obs = _obs\n",
    "        ep_reward += reward\n",
    "        ep_steps += 1\n",
    "        total_steps += 1\n",
    "\n",
    "        # tensorboard\n",
    "        if USE_TENSORBOARD:\n",
    "            writer.add_scalar('reward', ep_reward, i + 1)\n",
    "        \n",
    "        # learning\n",
    "        if len(rep_memory) >= learn_start:\n",
    "            if len(rep_memory) == learn_start:\n",
    "                is_learned = True\n",
    "                print('\\n==========  Learning Start  ==========')\n",
    "            train(net, target_net, rep_memory)\n",
    "\n",
    "            # epsilon decay\n",
    "            epsilon -= 1 / 10**4\n",
    "            epsilon = max(eps_min, epsilon)\n",
    "\n",
    "        if done:\n",
    "            rewards.append(ep_reward)\n",
    "            n_dones += 1\n",
    "            print('{:3} Episode in {:3} steps, reward {:.2f}'.format(i + 1, ep_steps, ep_reward))\n",
    "            if is_learned:\n",
    "                # sync target net\n",
    "                if n_dones % update_frq == 0:\n",
    "                    target_net.load_state_dict(net.state_dict())\n",
    "\n",
    "            # evaluate\n",
    "            if len(rewards) > 20:\n",
    "                if np.mean(rewards[-21:-1]) >= 200:\n",
    "                    is_solved = True\n",
    "                    print('\\nCartpole is sloved! {:3} Episode in {:3} steps'.format(i + 1, total_steps))\n",
    "            break\n",
    "    \n",
    "    if is_solved:                  \n",
    "        break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
