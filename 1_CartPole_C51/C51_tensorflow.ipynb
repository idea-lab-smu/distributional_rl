{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Distributional Perspective on Reinforcement Learning\n",
    "\n",
    " 이 jupyter notebook은 논문 [A Distributional Perspective on Reinforcement Learning](https://arxiv.org/abs/1707.06887)의 알고리즘 (C51)을 gym의 Cartpole 환경에서 구현한 notebook 입니다. 본 notebook의 경우 알고리즘의 구현에 관련된 설명 위주로 할 예정입니다. 논문에 대한 더 자세한 내용은 readme를 참고해주세요!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 불러오기\n",
    "\n",
    "본 알고리즘의 구현을 위한 라이브러리들을 불러오는 부분입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 파라미터 설정\n",
    "\n",
    "알고리즘의 구현을 위한 파라미터들을 설정하는 부분입니다.<br>\n",
    "C51이 [Deep Q Network](https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf)에 비해 추가되는 파라미터는 support와 관련된 것들입니다.<br>\n",
    "\n",
    "Supports는 각각이 value를 의미합니다. <br>\n",
    "그리고 해당 support가 가지는 값은 해당 support의 값을 받을 확률을 나타냅니다. <br>\n",
    "그리고 이 모든 support와 그 값들의 기대값이 Q값이 됩니다. <br>\n",
    "\n",
    "다음의 3가지 파라미터들을 설정해주어야 합니다.\n",
    "- $N$: Support의 수\n",
    "- $V_{min}$: Support의 최소값\n",
    "- $V_{max}$: Support의 최대값\n",
    "\n",
    "해당 파라미터들에 대한 설명은 다음과 같습니다. <br>\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://github.com/reinforcement-learning-kr/distributional_rl/blob/master/1_CartPole_C51/Images/support_and_prob.png?raw=true\" alt=\"support and probability\" style=\"width:1000px;\"/>\n",
    "</center>\n",
    "\n",
    "이외의 파라미터들에 대한 설명은 다음과 같습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 네트워크 설정\n",
    "\n",
    "C51 알고리즘은 support들은($z_i$) 고정한 상태로 각 value를 받을 확률을($p_i$) 추정합니다. <br>\n",
    "이때 다음의 그림과 같이 네트워크의 output이 각 support에 대한 값을 추정하고 이 값들을 softmax해주어 확률로 표현합니다.<br>\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://github.com/reinforcement-learning-kr/distributional_rl/blob/master/1_CartPole_C51/Images/network_output.png?raw=true\" alt=\"network output\" style=\"width:800px;\"/>\n",
    "</center>\n",
    "\n",
    "이 distribution은 각 action에 대해서 구해주어야합니다. \n",
    "그렇기 때문에 network의 output의 개수 -> $|A|\\times N$ ($|A|$: Action의 수, $N$: support의 수)\n",
    "\n",
    "DQN과 동일하게 network은 `일반 network`와 `target network` 2가지가 필요합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 일반 네트워크 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 타겟 네트워크 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Loss 설정 및 학습\n",
    "\n",
    " C51의 loss는 `target distribution`과 `추정된 distribution 중 실제 취한 action에 대한 distribution`간의 차이입니다. <br>\n",
    "\n",
    " 원래 distributional RL의 수렴성을 확보하기 위해서는 `Wasserstein Distance`를 이용하여 두 distribution의 차이를 결정해주어야 합니다. <br>\n",
    " 하지만 본 논문에서는 `Cross entropy`를 이용하여 두 distribution의 차이를 결정합니다. \n",
    " <center>\n",
    "    <img src=\"https://github.com/reinforcement-learning-kr/distributional_rl/blob/master/1_CartPole_C51/Images/cross_entropy_loss.png?raw=true\" alt=\"Cross entropy loss\" style=\"width:800px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Session 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 함수 설정\n",
    "\n",
    " 이 부분은 알고리즘을 구현하는데 필요한 함수들을 구현해놓은 부분입니다. <br>\n",
    " 각 함수에 대한 간단한 설명은 다음과 같습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Main\n",
    "\n",
    " 이 부분은 메인 알고리즘입니다. <br>\n",
    " 진행 순서는 다음과 같습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
