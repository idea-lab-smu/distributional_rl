{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Distributional Perspective on Reinforcement Learning\n",
    "\n",
    " 이 jupyter notebook은 논문 [A Distributional Perspective on Reinforcement Learning](https://arxiv.org/abs/1707.06887)의 알고리즘 (C51)을 gym의 Cartpole 환경에서 구현한 notebook 입니다. 본 notebook의 경우 알고리즘의 구현에 관련된 설명 위주로 할 예정입니다. 논문에 대한 더 자세한 내용은 readme를 참고해주세요!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 불러오기\n",
    "\n",
    "본 알고리즘의 구현을 위한 라이브러리들을 불러오는 부분입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 파라미터 설정\n",
    "\n",
    "알고리즘의 구현을 위한 파라미터들을 설정하는 부분입니다.<br>\n",
    "C51이 [Deep Q Network](https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf)에 비해 추가되는 파라미터는 support와 관련된 것들입니다.<br>\n",
    "\n",
    "Supports는 각각이 value를 의미합니다. <br>\n",
    "그리고 해당 support가 가지는 값은 해당 support의 값을 받을 확률을 나타냅니다. <br>\n",
    "그리고 이 모든 support와 그 값들의 기대값이 Q값이 됩니다. <br>\n",
    "\n",
    "다음의 3가지 파라미터들을 설정해주어야 합니다.\n",
    "- $N$: Support의 수\n",
    "- $V_{min}$: Support의 최소값\n",
    "- $V_{max}$: Support의 최대값\n",
    "\n",
    "해당 파라미터들에 대한 설명은 다음과 같습니다. <br>\n",
    "<img src=\"./Images/support_and_prob.png\" alt=\"bimodal\" class = \"center\" style=\"width: 800px;\"/>\n",
    "\n",
    "이외의 파라미터들에 대한 설명은 다음과 같습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 네트워크 설정\n",
    "\n",
    "C51 알고리즘은 support들은($z_i$) 고정한 상태로 각 value를 받을 확률을($p_i$) 추정합니다. <br>\n",
    "이때 다음의 그림과 같이 네트워크의 output이 각 support에 대한 값을 추정하고 이 값들을 softmax해주어 확률로 표현합니다.<br>\n",
    "<img src=\"./Images/network_output.png\" alt=\"network output\" class = \"center\" style=\"width: 800px;\"/>\n",
    "\n",
    "이 distribution은 각 action에 대해서 구해주어야합니다. \n",
    "그렇기 때문에 network의 output의 개수 -> $|A|\\times N$ ($|A|$: Action의 수, $N$: support의 수)\n",
    "\n",
    "DQN과 동일하게 network은 `일반 network`와 `target network` 2가지가 필요하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
